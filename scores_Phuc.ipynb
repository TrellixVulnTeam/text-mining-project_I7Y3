{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from rouge import Rouge\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizerFast\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import bleurt.score as bleurt_score\n",
    "\n",
    "# model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, ensemble\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metric_from_groupSize = lambda n: ('rouge-%d' % n)\n",
    "\n",
    "def calculate_recall(ref, candidate, group_size=1):\n",
    "    #print(ref)\n",
    "    try: \n",
    "        #print(candidate)\n",
    "        #Instantiate Rouge\n",
    "        rouge_metric = get_metric_from_groupSize(group_size)\n",
    "        rouge_stat = \"r\"\n",
    "        rouge = Rouge(metrics=[rouge_metric], stats=[rouge_stat])\n",
    "        outcome = rouge.get_scores(candidate, ref)\n",
    "        return outcome[0][rouge_metric][rouge_stat]\n",
    "    except:\n",
    "        return None\n",
    "          \n",
    "def calculate_precision(ref, candidate, group_size=1):\n",
    "    try:\n",
    "        #Instantiate Rouge\n",
    "        rouge_metric = get_metric_from_groupSize(group_size)\n",
    "        rouge_stat = \"p\"\n",
    "        rouge = Rouge(metrics=[rouge_metric], stats=[rouge_stat])\n",
    "\n",
    "        outcome = rouge.get_scores(candidate, ref)\n",
    "        return outcome[0][rouge_metric][rouge_stat]\n",
    "    except:\n",
    "        return None    \n",
    "def calculate_f1(ref, candidate, group_size=1):\n",
    "    try:\n",
    "        #Instantiate Rouge\n",
    "        rouge_metric = get_metric_from_groupSize(group_size)\n",
    "        rouge_stat = \"f\"\n",
    "        rouge = Rouge(metrics=[rouge_metric], stats=[rouge_stat])\n",
    "\n",
    "        outcome = rouge.get_scores(candidate, ref)\n",
    "        return outcome[0][rouge_metric][rouge_stat]\n",
    "    except:\n",
    "        return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLEU(ref, candidate, group_size):\n",
    "    \n",
    "    ref = ref.lower().split()\n",
    "    candidate = candidate.lower().split()\n",
    "\n",
    "    if(group_size > 1):\n",
    "        ref = formGroups(ref, group_size)\n",
    "        candidate = formGroups(candidate, group_size)\n",
    "\n",
    "    # compute word frequencies for the references and the candidate\n",
    "    ref_counts = Counter(ref)\n",
    "    candidate_counts = Counter(candidate)\n",
    "\n",
    "    covered = 0\n",
    "    total = 0\n",
    "    \n",
    "    # compute the coverage for each word\n",
    "    for word, count in candidate_counts.items():\n",
    "        covered += min(count, ref_counts[word])\n",
    "        total += count\n",
    "    \n",
    "    return covered / len(candidate_counts)\n",
    "\n",
    "def formGroups(words, group_size):\n",
    "\n",
    "    if(group_size > len(words)):\n",
    "        return words\n",
    "\n",
    "    #Form groups\n",
    "    to_return = []\n",
    "    i = 0\n",
    "    while (i + group_size - 1) < len(words):\n",
    "        to_return.append(' '.join(words[i:i + group_size]))\n",
    "        i+=1\n",
    "\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BLEU\n",
    "def calculate_bleu(dataframe, reference_col='reference', translation_col='translation', word_group_size=1):\n",
    "    series_data = [BLEU(row[reference_col], row[translation_col], group_size= word_group_size) for idx, row in dataframe.iterrows()]\n",
    "    return pd.Series(data=series_data, index=dataframe.index) \n",
    "\n",
    "#ROUGE\n",
    "def calculate_rouge_recall(dataframe, reference_col='reference', translation_col='translation', word_group_size=1):\n",
    "    series_data = [calculate_recall(row[reference_col], row[translation_col], word_group_size) for idx, row in dataframe.iterrows()]\n",
    "    return pd.Series(data=series_data, index=dataframe.index) \n",
    "\n",
    "def calculate_rouge_precision(dataframe, reference_col='reference', translation_col='translation', word_group_size=1):\n",
    "    series_data = [calculate_precision(row[reference_col], row[translation_col], word_group_size) for idx, row in dataframe.iterrows()]\n",
    "    return pd.Series(data=series_data, index=dataframe.index) \n",
    "\n",
    "def calculate_rouge_f1(dataframe, reference_col='reference', translation_col='translation', word_group_size=1):\n",
    "    series_data = [calculate_f1(row[reference_col], row[translation_col], word_group_size) for idx, row in dataframe.iterrows()]\n",
    "    return pd.Series(data=series_data, index=dataframe.index) \n",
    "\n",
    "#AUXILIARY\n",
    "def getCSV(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "\n",
    "def initBLEURT(csv):\n",
    "    checkpoint = \"bleurt\\\\test_checkpoint\"\n",
    "    scorer = bleurt_score.BleurtScorer(checkpoint)\n",
    "    references = csv.reference\n",
    "    candidates = csv.translation\n",
    "    print(\"BLEURT calculating...\")\n",
    "    scores_bluert = [scorer.score(references=[row[\"reference\"]],candidates= [row[\"translation\"]])[0] for idx, row in csv.iterrows()]\n",
    "    return scores_bluert\n",
    "\n",
    "#MAIN\n",
    "def main(filePath):\n",
    "    #Get file path from arguments\n",
    "    #filePath = sys.argv[1]\n",
    "    \n",
    "    #Import CSV\n",
    "    csv = getCSV(filePath)\n",
    "\n",
    "    #BLEU calculation\n",
    "    csv['bleu_w1'] = calculate_bleu(csv)\n",
    "    csv['bleu_w2'] = calculate_bleu(csv, word_group_size=2)\n",
    "    print(\"BLEU calculated...\")\n",
    "\n",
    "    #ROUGE calculation\n",
    "    csv['rouge_recall_w1'] = calculate_rouge_recall(csv)\n",
    "    csv['rouge_precision_w1'] = calculate_rouge_precision(csv)\n",
    "    csv['rouge_f1_w1'] = calculate_rouge_f1(csv)\n",
    "    print(\"ROUGE 1-gram calculated...\")\n",
    "\n",
    "    csv['rouge_precision_w2'] = calculate_rouge_precision(csv, word_group_size=2)\n",
    "    csv['rouge_recall_w2'] = calculate_rouge_recall(csv, word_group_size=2)\n",
    "    csv['rouge_f1_w2'] = calculate_rouge_f1(csv, word_group_size=2)\n",
    "    print(\"ROUGE 2-gram calculated...\")   \n",
    "    csv['BLEURT'] = initBLEURT(csv)\n",
    "\n",
    "    #PRINT\n",
    "    #print(csv)\n",
    "    return csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\text-mining-project\\\\corpus\"\n",
    "corpus = \"\\\\en-zh\"\n",
    "filePath = path + corpus + \"\\\\scores.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU calculated...\n",
      "ROUGE 1-gram calculated...\n",
      "ROUGE 2-gram calculated...\n",
      "INFO:tensorflow:Reading checkpoint bleurt\\test_checkpoint.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint dbleurt_tiny\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:dbleurt_tiny\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n",
      "BLEURT calculating...\n"
     ]
    }
   ],
   "source": [
    "data = main(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "      <th>bleu_w1</th>\n",
       "      <th>bleu_w2</th>\n",
       "      <th>rouge_recall_w1</th>\n",
       "      <th>rouge_precision_w1</th>\n",
       "      <th>rouge_f1_w1</th>\n",
       "      <th>rouge_precision_w2</th>\n",
       "      <th>rouge_recall_w2</th>\n",
       "      <th>rouge_f1_w2</th>\n",
       "      <th>BLEURT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"In the GISS model's simulation, Venus' slow s...</td>\n",
       "      <td>GSIS的科学家AnthonyDelGenio在新闻稿中解释说：“在GISS模型的模拟模型中...</td>\n",
       "      <td>戈达德太空研究所科学家安东尼·德尔·杰尼奥在新闻发布会上解释说：“在戈达德太空研究所的模型模...</td>\n",
       "      <td>-1.171867</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ai Yanhan of China in the Women's 4 x 200m Fre...</td>\n",
       "      <td>中国在英国女性4x200mFreestreyWTE中的最后被称为：“中国14岁的孩子从球下降...</td>\n",
       "      <td>参加女子4x200米自由泳接力赛决赛的中国小将艾衍含被这样描述：“那名14岁的中国小姑娘犯了...</td>\n",
       "      <td>-2.255403</td>\n",
       "      <td>26.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.338784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Then came 2012, when nothing much went right f...</td>\n",
       "      <td>然后来到2012年，当她和她的队友们没有什么好处。</td>\n",
       "      <td>2012年，她和她的队友都不被看好。</td>\n",
       "      <td>-2.508996</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Since last year, Guodian Group has exported a ...</td>\n",
       "      <td>自去年以来，GoudianGroup从南非通过南非港口出口了163套风力发电项目。</td>\n",
       "      <td>自去年以来，国电集团共计有163套风电项目陆续从连云港港出口南非。</td>\n",
       "      <td>-2.416780</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some alleged that the Kempinski hotel simply \"...</td>\n",
       "      <td>一些人指称，Kempinski旅馆只是\"被捕\"，以满足阿拉伯客户的要求。</td>\n",
       "      <td>有人认为凯宾斯基酒店简直是为了满足阿拉伯客户的要求而“卑躬屈膝”。</td>\n",
       "      <td>-1.489676</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  \"In the GISS model's simulation, Venus' slow s...   \n",
       "1  Ai Yanhan of China in the Women's 4 x 200m Fre...   \n",
       "2  Then came 2012, when nothing much went right f...   \n",
       "3  Since last year, Guodian Group has exported a ...   \n",
       "4  Some alleged that the Kempinski hotel simply \"...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  GSIS的科学家AnthonyDelGenio在新闻稿中解释说：“在GISS模型的模拟模型中...   \n",
       "1  中国在英国女性4x200mFreestreyWTE中的最后被称为：“中国14岁的孩子从球下降...   \n",
       "2                          然后来到2012年，当她和她的队友们没有什么好处。   \n",
       "3          自去年以来，GoudianGroup从南非通过南非港口出口了163套风力发电项目。   \n",
       "4               一些人指称，Kempinski旅馆只是\"被捕\"，以满足阿拉伯客户的要求。   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  戈达德太空研究所科学家安东尼·德尔·杰尼奥在新闻发布会上解释说：“在戈达德太空研究所的模型模... -1.171867       50.0   \n",
       "1  参加女子4x200米自由泳接力赛决赛的中国小将艾衍含被这样描述：“那名14岁的中国小姑娘犯了... -2.255403       26.5   \n",
       "2                                 2012年，她和她的队友都不被看好。 -2.508996       21.0   \n",
       "3                  自去年以来，国电集团共计有163套风电项目陆续从连云港港出口南非。 -2.416780       23.0   \n",
       "4                  有人认为凯宾斯基酒店简直是为了满足阿拉伯客户的要求而“卑躬屈膝”。 -1.489676       45.0   \n",
       "\n",
       "   annotators  bleu_w1  bleu_w2  rouge_recall_w1  rouge_precision_w1  \\\n",
       "0           1      0.0      0.0              0.0                 0.0   \n",
       "1           2      0.0      0.0              0.0                 0.0   \n",
       "2           1      0.0      0.0              0.0                 0.0   \n",
       "3           1      0.0      0.0              0.0                 0.0   \n",
       "4           7      0.0      0.0              0.0                 0.0   \n",
       "\n",
       "   rouge_f1_w1  rouge_precision_w2  rouge_recall_w2  rouge_f1_w2    BLEURT  \n",
       "0          0.0                 0.0              0.0          0.0  0.193127  \n",
       "1          0.0                 0.0              0.0          0.0  0.338784  \n",
       "2          0.0                 0.0              0.0          0.0  0.108004  \n",
       "3          0.0                 0.0              0.0          0.0  0.303250  \n",
       "4          0.0                 0.0              0.0          0.0  0.130959  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_CV_pipe(x_train, y_train, model, n_splits = 5):\n",
    "    all_scores = []\n",
    "    # set up k-fold\n",
    "    kf = KFold(n_splits=5)\n",
    "    oof_prediction = np.zeros((len(x_train),))\n",
    "    test_preds = 0\n",
    "    for  _, (trn_idx, val_idx) in tqdm(enumerate(kf.split(x_train, y_train))):\n",
    "        # set up the splitted data\n",
    "        train       , val        = x_train.loc[trn_idx,:], x_train.loc[val_idx,:]\n",
    "        train_target, val_target = y_train[trn_idx], y_train[val_idx]      \n",
    "        #print(train,val)\n",
    "        # encode     \n",
    "        # model fitting\n",
    "        model.fit(train, train_target)\n",
    "        # get predicted values for oof data and whole test set\n",
    "        temp_oof = model.predict(val)\n",
    "        # get predicted values for whole data set aggregate from each fold iter\n",
    "        oof_prediction[val_idx] = temp_oof    \n",
    "        fold_score = pd.Series(val_target).corr(pd.Series(temp_oof,index = val_idx),method='pearson')\n",
    "        print(fold_score)\n",
    "        all_scores.append(fold_score)               \n",
    "    return  oof_prediction, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 120,\n",
    "          'max_depth': 6,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.reset_index(drop=True,inplace=True)\n",
    "data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-106-a31d82d47031>:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for  _, (trn_idx, val_idx) in tqdm(enumerate(kf.split(x_train, y_train))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a948dbd75c3e4c3a9cc11db54f203fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11056370827333754\n",
      "0.15099479571549362\n",
      "0.20296832592487027\n",
      "0.18770508141172668\n",
      "0.15157997357922964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0977554939587571"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scores = pd.DataFrame(scaler.fit_transform(data[['BLEURT']]),columns=['BLEURT'], index = data.index)\n",
    "model = ensemble.GradientBoostingRegressor(**params)\n",
    "oof_prediction, all_scores = kfold_CV_pipe(scores,data['z-score'],model)\n",
    "\n",
    "data['z-score'].corr(pd.Series(oof_prediction,index = data.index),method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15199563182865442"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['z-score'].corr(data['BLEURT'],method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bleurt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint bleurt\\test_checkpoint.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint dbleurt_tiny\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:dbleurt_tiny\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"bleurt\\\\test_checkpoint\"\n",
    "scorer = bleurt_score.BleurtScorer(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = getCSV(filePath)\n",
    "references = csv.reference\n",
    "candidates = csv.translation\n",
    "#scores_bluert = scorer.score(references=references, candidates=candidates)\n",
    "scores_bluert = [scorer.score(references=[row[\"reference\"]],candidates= [row[\"translation\"]])[0] for idx, row in csv.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BLEURT'] = scores_bluert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scores = pd.DataFrame(scaler.fit_transform(data.loc[:,'bleu_w1':]),columns=data.loc[:,'bleu_w1':].columns, index = data.loc[:,'bleu_w1':].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu_w1</th>\n",
       "      <th>bleu_w2</th>\n",
       "      <th>rouge_recall_w1</th>\n",
       "      <th>rouge_precision_w1</th>\n",
       "      <th>rouge_f1_w1</th>\n",
       "      <th>rouge_precision_w2</th>\n",
       "      <th>rouge_recall_w2</th>\n",
       "      <th>rouge_f1_w2</th>\n",
       "      <th>BLEURT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.264540</td>\n",
       "      <td>0.137482</td>\n",
       "      <td>0.634414</td>\n",
       "      <td>1.195416</td>\n",
       "      <td>0.948848</td>\n",
       "      <td>0.158922</td>\n",
       "      <td>-0.079202</td>\n",
       "      <td>0.044152</td>\n",
       "      <td>-0.028511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.465324</td>\n",
       "      <td>0.771770</td>\n",
       "      <td>0.064105</td>\n",
       "      <td>0.398461</td>\n",
       "      <td>0.256429</td>\n",
       "      <td>0.802442</td>\n",
       "      <td>0.549969</td>\n",
       "      <td>0.691346</td>\n",
       "      <td>-0.406516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.141584</td>\n",
       "      <td>0.737533</td>\n",
       "      <td>1.018991</td>\n",
       "      <td>0.591662</td>\n",
       "      <td>0.837755</td>\n",
       "      <td>0.767706</td>\n",
       "      <td>1.044318</td>\n",
       "      <td>0.921315</td>\n",
       "      <td>0.821842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.067486</td>\n",
       "      <td>-0.186870</td>\n",
       "      <td>0.966340</td>\n",
       "      <td>0.162326</td>\n",
       "      <td>0.550251</td>\n",
       "      <td>-0.170150</td>\n",
       "      <td>0.220403</td>\n",
       "      <td>0.009019</td>\n",
       "      <td>-1.462404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.205764</td>\n",
       "      <td>-0.803139</td>\n",
       "      <td>-0.980406</td>\n",
       "      <td>-1.358927</td>\n",
       "      <td>-1.208427</td>\n",
       "      <td>-0.820398</td>\n",
       "      <td>-0.646875</td>\n",
       "      <td>-0.743953</td>\n",
       "      <td>-0.455236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11580</th>\n",
       "      <td>-0.094127</td>\n",
       "      <td>0.458745</td>\n",
       "      <td>0.064105</td>\n",
       "      <td>-0.132842</td>\n",
       "      <td>-0.016103</td>\n",
       "      <td>0.536640</td>\n",
       "      <td>0.691212</td>\n",
       "      <td>0.631039</td>\n",
       "      <td>0.638268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11581</th>\n",
       "      <td>-0.115924</td>\n",
       "      <td>-0.747114</td>\n",
       "      <td>-0.294979</td>\n",
       "      <td>-0.248343</td>\n",
       "      <td>-0.254568</td>\n",
       "      <td>-0.965907</td>\n",
       "      <td>-0.978018</td>\n",
       "      <td>-0.973118</td>\n",
       "      <td>-0.927007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11582</th>\n",
       "      <td>0.604318</td>\n",
       "      <td>1.269765</td>\n",
       "      <td>0.402066</td>\n",
       "      <td>0.444661</td>\n",
       "      <td>0.460827</td>\n",
       "      <td>0.852966</td>\n",
       "      <td>0.819614</td>\n",
       "      <td>0.860205</td>\n",
       "      <td>1.008398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11583</th>\n",
       "      <td>0.508525</td>\n",
       "      <td>0.712549</td>\n",
       "      <td>0.064105</td>\n",
       "      <td>0.566241</td>\n",
       "      <td>0.332870</td>\n",
       "      <td>0.742359</td>\n",
       "      <td>0.412011</td>\n",
       "      <td>0.585206</td>\n",
       "      <td>-0.565352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11584</th>\n",
       "      <td>0.665128</td>\n",
       "      <td>0.165283</td>\n",
       "      <td>-0.000671</td>\n",
       "      <td>0.141970</td>\n",
       "      <td>0.097067</td>\n",
       "      <td>0.008489</td>\n",
       "      <td>-0.063705</td>\n",
       "      <td>-0.016252</td>\n",
       "      <td>0.140559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11585 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bleu_w1   bleu_w2  rouge_recall_w1  rouge_precision_w1  rouge_f1_w1  \\\n",
       "0      1.264540  0.137482         0.634414            1.195416     0.948848   \n",
       "1      0.465324  0.771770         0.064105            0.398461     0.256429   \n",
       "2      1.141584  0.737533         1.018991            0.591662     0.837755   \n",
       "3     -0.067486 -0.186870         0.966340            0.162326     0.550251   \n",
       "4     -1.205764 -0.803139        -0.980406           -1.358927    -1.208427   \n",
       "...         ...       ...              ...                 ...          ...   \n",
       "11580 -0.094127  0.458745         0.064105           -0.132842    -0.016103   \n",
       "11581 -0.115924 -0.747114        -0.294979           -0.248343    -0.254568   \n",
       "11582  0.604318  1.269765         0.402066            0.444661     0.460827   \n",
       "11583  0.508525  0.712549         0.064105            0.566241     0.332870   \n",
       "11584  0.665128  0.165283        -0.000671            0.141970     0.097067   \n",
       "\n",
       "       rouge_precision_w2  rouge_recall_w2  rouge_f1_w2    BLEURT  \n",
       "0                0.158922        -0.079202     0.044152 -0.028511  \n",
       "1                0.802442         0.549969     0.691346 -0.406516  \n",
       "2                0.767706         1.044318     0.921315  0.821842  \n",
       "3               -0.170150         0.220403     0.009019 -1.462404  \n",
       "4               -0.820398        -0.646875    -0.743953 -0.455236  \n",
       "...                   ...              ...          ...       ...  \n",
       "11580            0.536640         0.691212     0.631039  0.638268  \n",
       "11581           -0.965907        -0.978018    -0.973118 -0.927007  \n",
       "11582            0.852966         0.819614     0.860205  1.008398  \n",
       "11583            0.742359         0.412011     0.585206 -0.565352  \n",
       "11584            0.008489        -0.063705    -0.016252  0.140559  \n",
       "\n",
       "[11585 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for normal score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>pcorr</th>\n",
       "      <th>kendallcorr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bleu_w1</th>\n",
       "      <td>1.053754</td>\n",
       "      <td>0.404921</td>\n",
       "      <td>0.271061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bleu_w2</th>\n",
       "      <td>1.079262</td>\n",
       "      <td>0.390275</td>\n",
       "      <td>0.272864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge_recall_w1</th>\n",
       "      <td>1.113440</td>\n",
       "      <td>0.370650</td>\n",
       "      <td>0.249050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge_precision_w1</th>\n",
       "      <td>1.019766</td>\n",
       "      <td>0.424436</td>\n",
       "      <td>0.286600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge_f1_w1</th>\n",
       "      <td>1.035963</td>\n",
       "      <td>0.415136</td>\n",
       "      <td>0.279233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge_precision_w2</th>\n",
       "      <td>1.089080</td>\n",
       "      <td>0.384637</td>\n",
       "      <td>0.267882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge_recall_w2</th>\n",
       "      <td>1.135497</td>\n",
       "      <td>0.357986</td>\n",
       "      <td>0.247705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge_f1_w2</th>\n",
       "      <td>1.100779</td>\n",
       "      <td>0.377920</td>\n",
       "      <td>0.260021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEURT</th>\n",
       "      <td>0.940529</td>\n",
       "      <td>0.469932</td>\n",
       "      <td>0.329338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mse     pcorr  kendallcorr\n",
       "bleu_w1             1.053754  0.404921     0.271061\n",
       "bleu_w2             1.079262  0.390275     0.272864\n",
       "rouge_recall_w1     1.113440  0.370650     0.249050\n",
       "rouge_precision_w1  1.019766  0.424436     0.286600\n",
       "rouge_f1_w1         1.035963  0.415136     0.279233\n",
       "rouge_precision_w2  1.089080  0.384637     0.267882\n",
       "rouge_recall_w2     1.135497  0.357986     0.247705\n",
       "rouge_f1_w2         1.100779  0.377920     0.260021\n",
       "BLEURT              0.940529  0.469932     0.329338"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = np.array([])\n",
    "pcorr = np.array([])\n",
    "kendallcorr = np.array([])\n",
    "metrics = scores.columns\n",
    "for col in scores.columns:\n",
    "    mse = np.append(mse,mean_squared_error(data['z-score'],scores[col]))\n",
    "    pcorr = np.append(pcorr,data['z-score'].corr(scores[col],method='pearson'))\n",
    "    kendallcorr = np.append(kendallcorr,data['z-score'].corr(scores[col],method='kendall'))\n",
    "    \n",
    "pd.DataFrame({'mse':mse,'pcorr':pcorr,'kendallcorr':kendallcorr},index = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= scores\n",
    "y= data['z-score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=13)\n",
    "\n",
    "params = {'n_estimators': 120,\n",
    "          'max_depth': 6,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.01, max_depth=6, min_samples_split=5,\n",
       "                          n_estimators=120)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ensemble.GradientBoostingRegressor(**params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 0.5194\n",
      "The mean squared error (MSE) on test set: 0.5888\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_train, model.predict(X_train))\n",
    "print(\"The mean squared error (MSE) on train set: {:.4f}\".format(mse))\n",
    "mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = pd.Series(reg.predict(X_test),index = y_test.index,name = 'Predict_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_score =pd.merge(data['z-score'],y_predict,left_index= True,right_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 0.6510223507551757\n",
      "pcorr 0.5068492287785946\n",
      "kendall 0.3629815342755539\n"
     ]
    }
   ],
   "source": [
    "print('mse',mean_squared_error(merged_score['z-score'],merged_score['Predict_score']))\n",
    "print('pcorr',merged_score['z-score'].corr(merged_score['Predict_score'],method='pearson'))\n",
    "print('kendall',merged_score['z-score'].corr(merged_score['Predict_score'],method='kendall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_results(scores,z_score)\n",
    "    mse = np.array([])\n",
    "    pcorr = np.array([])\n",
    "    kendallcorr = np.array([])\n",
    "    metrics = scores.columns\n",
    "    for col in scores.columns:\n",
    "        mse = np.append(mse,mean_squared_error(z_score,scores[col]))\n",
    "        pcorr = np.append(pcorr,z_score.corr(scores[col],method='pearson'))\n",
    "        kendallcorr = np.append(kendallcorr,z_score.corr(scores[col],method='kendall'))\n",
    "    pd.DataFrame({'mse':mse,'pcorr':pcorr,'kendallcorr':kendallcorr},index = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_CV_pipe(x_train, y_train, model, n_splits = 5):\n",
    "    all_scores = []\n",
    "    # set up k-fold\n",
    "    kf = KFold(n_splits=5)\n",
    "    oof_prediction = np.zeros((len(scores),))\n",
    "    test_preds = 0\n",
    "    for  _, (trn_idx, val_idx) in tqdm(enumerate(kf.split(scores, data['z-score']))):\n",
    "        # set up the splitted data\n",
    "        train       , val        = scores.loc[trn_idx,:], scores.loc[val_idx,:]\n",
    "        train_target, val_target = data['z-score'][trn_idx], data['z-score'][val_idx]      \n",
    "        #print(train,val)\n",
    "        # encode     \n",
    "        # model fitting\n",
    "        model.fit(train, train_target)\n",
    "        # get predicted values for oof data and whole test set\n",
    "        temp_oof = model.predict(val)\n",
    "        # get predicted values for whole data set aggregate from each fold iter\n",
    "        oof_prediction[val_idx] = temp_oof    \n",
    "        fold_score = pd.Series(val_target).corr(pd.Series(temp_oof,index = val_idx),method='pearson')\n",
    "        print(fold_score)\n",
    "        all_scores.append(fold_score)               \n",
    "    return  oof_prediction, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-82-0de1d9b2030f>:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for  _, (trn_idx, val_idx) in tqdm(enumerate(kf.split(scores, data['z-score']))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ee7485735b4c5f88c1b0acc583277b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5151114418970998\n",
      "0.45190028203146526\n",
      "0.5390717229564809\n",
      "0.5361070573926131\n",
      "0.5445100717320295\n"
     ]
    }
   ],
   "source": [
    "model = ensemble.GradientBoostingRegressor(**params)\n",
    "oof_prediction, all_scores = kfold_CV_pipe(scores,data['z-score'],model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5173917437819486"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['z-score'].corr(pd.Series(oof_prediction,index = data.index),method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
