{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from rouge import Rouge\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizerFast\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import bleurt.score as bleurt_score\n",
    "\n",
    "# model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, ensemble\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metric_from_groupSize = lambda n: ('rouge-%d' % n)\n",
    "\n",
    "def calculate_recall(ref, candidate, group_size=1):\n",
    "    #print(ref)\n",
    "    #print(candidate)\n",
    "    #Instantiate Rouge\n",
    "    rouge_metric = get_metric_from_groupSize(group_size)\n",
    "    rouge_stat = \"r\"\n",
    "    rouge = Rouge(metrics=[rouge_metric], stats=[rouge_stat])\n",
    "\n",
    "    outcome = rouge.get_scores(candidate, ref)\n",
    "    return outcome[0][rouge_metric][rouge_stat]\n",
    "\n",
    "def calculate_precision(ref, candidate, group_size=1):\n",
    "\n",
    "    #Instantiate Rouge\n",
    "    rouge_metric = get_metric_from_groupSize(group_size)\n",
    "    rouge_stat = \"p\"\n",
    "    rouge = Rouge(metrics=[rouge_metric], stats=[rouge_stat])\n",
    "\n",
    "    outcome = rouge.get_scores(candidate, ref)\n",
    "    return outcome[0][rouge_metric][rouge_stat]\n",
    "\n",
    "def calculate_f1(ref, candidate, group_size=1):\n",
    "\n",
    "    #Instantiate Rouge\n",
    "    rouge_metric = get_metric_from_groupSize(group_size)\n",
    "    rouge_stat = \"f\"\n",
    "    rouge = Rouge(metrics=[rouge_metric], stats=[rouge_stat])\n",
    "\n",
    "    outcome = rouge.get_scores(candidate, ref)\n",
    "    return outcome[0][rouge_metric][rouge_stat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLEU(ref, candidate, group_size):\n",
    "    \n",
    "    ref = ref.lower().split()\n",
    "    candidate = candidate.lower().split()\n",
    "\n",
    "    if(group_size > 1):\n",
    "        ref = formGroups(ref, group_size)\n",
    "        candidate = formGroups(candidate, group_size)\n",
    "\n",
    "    # compute word frequencies for the references and the candidate\n",
    "    ref_counts = Counter(ref)\n",
    "    candidate_counts = Counter(candidate)\n",
    "\n",
    "    covered = 0\n",
    "    total = 0\n",
    "    \n",
    "    # compute the coverage for each word\n",
    "    for word, count in candidate_counts.items():\n",
    "        covered += min(count, ref_counts[word])\n",
    "        total += count\n",
    "    \n",
    "    return covered / len(candidate_counts)\n",
    "\n",
    "def formGroups(words, group_size):\n",
    "\n",
    "    if(group_size > len(words)):\n",
    "        return words\n",
    "\n",
    "    #Form groups\n",
    "    to_return = []\n",
    "    i = 0\n",
    "    while (i + group_size - 1) < len(words):\n",
    "        to_return.append(' '.join(words[i:i + group_size]))\n",
    "        i+=1\n",
    "\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BLEU\n",
    "def calculate_bleu(dataframe, reference_col='reference', translation_col='translation', word_group_size=1):\n",
    "    series_data = [BLEU(row[reference_col], row[translation_col], group_size= word_group_size) for idx, row in dataframe.iterrows()]\n",
    "    return pd.Series(data=series_data, index=dataframe.index) \n",
    "\n",
    "#ROUGE\n",
    "def calculate_rouge_recall(dataframe, reference_col='reference', translation_col='translation', word_group_size=1):\n",
    "    series_data = [calculate_recall(row[reference_col], row[translation_col], word_group_size) for idx, row in dataframe.iterrows()]\n",
    "    return pd.Series(data=series_data, index=dataframe.index) \n",
    "\n",
    "def calculate_rouge_precision(dataframe, reference_col='reference', translation_col='translation', word_group_size=1):\n",
    "    series_data = [calculate_precision(row[reference_col], row[translation_col], word_group_size) for idx, row in dataframe.iterrows()]\n",
    "    return pd.Series(data=series_data, index=dataframe.index) \n",
    "\n",
    "def calculate_rouge_f1(dataframe, reference_col='reference', translation_col='translation', word_group_size=1):\n",
    "    series_data = [calculate_f1(row[reference_col], row[translation_col], word_group_size) for idx, row in dataframe.iterrows()]\n",
    "    return pd.Series(data=series_data, index=dataframe.index) \n",
    "\n",
    "#AUXILIARY\n",
    "def getCSV(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "\n",
    "def initBLEURT(csv):\n",
    "    checkpoint = \"bleurt\\\\test_checkpoint\"\n",
    "    scorer = bleurt_score.BleurtScorer(checkpoint)\n",
    "    references = csv.reference\n",
    "    candidates = csv.translation\n",
    "    print(\"BLEURT calculating...\")\n",
    "    scores_bluert = [scorer.score(references=[row[\"reference\"]],candidates= [row[\"translation\"]])[0] for idx, row in csv.iterrows()]\n",
    "    return scores_bluert\n",
    "\n",
    "#MAIN\n",
    "def main(filePath):\n",
    "    #Get file path from arguments\n",
    "    #filePath = sys.argv[1]\n",
    "    \n",
    "    #Import CSV\n",
    "    csv = getCSV(filePath)\n",
    "\n",
    "    #BLEU calculation\n",
    "    csv['bleu_w1'] = calculate_bleu(csv)\n",
    "    csv['bleu_w2'] = calculate_bleu(csv, word_group_size=2)\n",
    "    print(\"BLEU calculated...\")\n",
    "\n",
    "    #ROUGE calculation\n",
    "    csv['rouge_recall_w1'] = calculate_rouge_recall(csv)\n",
    "    csv['rouge_precision_w1'] = calculate_rouge_precision(csv)\n",
    "    csv['rouge_f1_w1'] = calculate_rouge_f1(csv)\n",
    "    print(\"ROUGE 1-gram calculated...\")\n",
    "\n",
    "    csv['rouge_precision_w2'] = calculate_rouge_precision(csv, word_group_size=2)\n",
    "    csv['rouge_recall_w2'] = calculate_rouge_recall(csv, word_group_size=2)\n",
    "    csv['rouge_f1_w2'] = calculate_rouge_f1(csv, word_group_size=2)\n",
    "    print(\"ROUGE 2-gram calculated...\")   \n",
    "    csv['BLEURT'] = initBLEURT(csv)\n",
    "\n",
    "    #PRINT\n",
    "    #print(csv)\n",
    "    return csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\text-mining-project\\\\corpus\"\n",
    "corpus = \"\\\\zh-en\"\n",
    "filePath = path + corpus + \"\\\\scores.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>他性格活泼，这对英国赛马来说是好事，但是除此之外，他还是一位不可思议的骑师。</td>\n",
       "      <td>His character is good for the British horse, b...</td>\n",
       "      <td>He's a lively character which is good for Brit...</td>\n",
       "      <td>0.625559</td>\n",
       "      <td>92.75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>近日刚搬至旧金山的一位28岁厨师本周被发现死于当地一家商场的楼梯间。</td>\n",
       "      <td>A 28 chef, who has just moved to San Francisco...</td>\n",
       "      <td>A 28-year-old chef who had recently moved to S...</td>\n",
       "      <td>0.550952</td>\n",
       "      <td>92.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>去年，有官员表示，胡克先生的团队所得出的结论是针对伊斯兰国炼油厂的空袭并未大幅削减恐怖组织的...</td>\n",
       "      <td>Last year, officials said Mr. Hooker's team ha...</td>\n",
       "      <td>Last year, officials said, Mr. Hooker's team c...</td>\n",
       "      <td>0.540814</td>\n",
       "      <td>89.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>尤其值得玩味的是政府对于饥饿民众们的回应，比如总统市民赫伯特·胡佛“别人的事我可管不了”的态度。</td>\n",
       "      <td>It is particularly interesting to note the gov...</td>\n",
       "      <td>Especially savory are the accounts of the gove...</td>\n",
       "      <td>-0.793944</td>\n",
       "      <td>49.50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>不过，从20世纪90年代至今，人类共进行了18次火星探测，而月球探测只进行了14次。</td>\n",
       "      <td>However, from the 1990s to the present, human ...</td>\n",
       "      <td>However, ever since the 1990s, a total of 18 h...</td>\n",
       "      <td>0.046532</td>\n",
       "      <td>77.50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26414</th>\n",
       "      <td>根据一份联合声明，“Wood Group 以及 Unite 和 RMT 工会可以确认我们已同...</td>\n",
       "      <td>According to a joint statement , \" Wood Group ...</td>\n",
       "      <td>\"Wood Group and the Unite and RMT unions can c...</td>\n",
       "      <td>0.563658</td>\n",
       "      <td>81.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26415</th>\n",
       "      <td>2016年8月12日，在里约奥运会女子50米步枪三种姿势比赛中，获得铜牌。</td>\n",
       "      <td>On August 12 , 2016 , a bronze medal was obtai...</td>\n",
       "      <td>On August 12, 2016, she won the bronze medal i...</td>\n",
       "      <td>-0.358579</td>\n",
       "      <td>64.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26416</th>\n",
       "      <td>这会给我带来太大的压力。</td>\n",
       "      <td>This will give me too big pressure.</td>\n",
       "      <td>That would have meant too much pressure.</td>\n",
       "      <td>0.554093</td>\n",
       "      <td>76.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26417</th>\n",
       "      <td>这名女性当场死亡。</td>\n",
       "      <td>The woman killed the spot.</td>\n",
       "      <td>She died at the scene.</td>\n",
       "      <td>-1.724330</td>\n",
       "      <td>36.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26418</th>\n",
       "      <td>参加者可以参观中央大厅、时代展室、仙人掌休息室和茶室。</td>\n",
       "      <td>Participants can visit the Central Hall , Time...</td>\n",
       "      <td>Attendees can tour the Central Hall, Period Ro...</td>\n",
       "      <td>1.232544</td>\n",
       "      <td>98.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26419 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  source  \\\n",
       "0                 他性格活泼，这对英国赛马来说是好事，但是除此之外，他还是一位不可思议的骑师。   \n",
       "1                     近日刚搬至旧金山的一位28岁厨师本周被发现死于当地一家商场的楼梯间。   \n",
       "2      去年，有官员表示，胡克先生的团队所得出的结论是针对伊斯兰国炼油厂的空袭并未大幅削减恐怖组织的...   \n",
       "3       尤其值得玩味的是政府对于饥饿民众们的回应，比如总统市民赫伯特·胡佛“别人的事我可管不了”的态度。   \n",
       "4             不过，从20世纪90年代至今，人类共进行了18次火星探测，而月球探测只进行了14次。   \n",
       "...                                                  ...   \n",
       "26414  根据一份联合声明，“Wood Group 以及 Unite 和 RMT 工会可以确认我们已同...   \n",
       "26415              2016年8月12日，在里约奥运会女子50米步枪三种姿势比赛中，获得铜牌。   \n",
       "26416                                       这会给我带来太大的压力。   \n",
       "26417                                          这名女性当场死亡。   \n",
       "26418                        参加者可以参观中央大厅、时代展室、仙人掌休息室和茶室。   \n",
       "\n",
       "                                               reference  \\\n",
       "0      His character is good for the British horse, b...   \n",
       "1      A 28 chef, who has just moved to San Francisco...   \n",
       "2      Last year, officials said Mr. Hooker's team ha...   \n",
       "3      It is particularly interesting to note the gov...   \n",
       "4      However, from the 1990s to the present, human ...   \n",
       "...                                                  ...   \n",
       "26414  According to a joint statement , \" Wood Group ...   \n",
       "26415  On August 12 , 2016 , a bronze medal was obtai...   \n",
       "26416                This will give me too big pressure.   \n",
       "26417                         The woman killed the spot.   \n",
       "26418  Participants can visit the Central Hall , Time...   \n",
       "\n",
       "                                             translation   z-score  avg-score  \\\n",
       "0      He's a lively character which is good for Brit...  0.625559      92.75   \n",
       "1      A 28-year-old chef who had recently moved to S...  0.550952      92.00   \n",
       "2      Last year, officials said, Mr. Hooker's team c...  0.540814      89.00   \n",
       "3      Especially savory are the accounts of the gove... -0.793944      49.50   \n",
       "4      However, ever since the 1990s, a total of 18 h...  0.046532      77.50   \n",
       "...                                                  ...       ...        ...   \n",
       "26414  \"Wood Group and the Unite and RMT unions can c...  0.563658      81.00   \n",
       "26415  On August 12, 2016, she won the bronze medal i... -0.358579      64.00   \n",
       "26416           That would have meant too much pressure.  0.554093      76.00   \n",
       "26417                             She died at the scene. -1.724330      36.00   \n",
       "26418  Attendees can tour the Central Hall, Period Ro...  1.232544      98.00   \n",
       "\n",
       "       annotators  \n",
       "0               4  \n",
       "1               4  \n",
       "2               5  \n",
       "3               4  \n",
       "4               4  \n",
       "...           ...  \n",
       "26414           1  \n",
       "26415           1  \n",
       "26416           1  \n",
       "26417           1  \n",
       "26418           1  \n",
       "\n",
       "[26419 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU calculated...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Reference is empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-4796240b14f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-34135bc53413>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(filePath)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m#ROUGE calculation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mcsv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rouge_recall_w1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_rouge_recall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[0mcsv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rouge_precision_w1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_rouge_precision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mcsv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rouge_f1_w1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_rouge_f1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-34135bc53413>\u001b[0m in \u001b[0;36mcalculate_rouge_recall\u001b[1;34m(dataframe, reference_col, translation_col, word_group_size)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#ROUGE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalculate_rouge_recall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreference_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'reference'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranslation_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'translation'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_group_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mseries_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcalculate_recall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreference_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtranslation_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_group_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseries_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-34135bc53413>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#ROUGE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalculate_rouge_recall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreference_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'reference'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranslation_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'translation'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_group_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mseries_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcalculate_recall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreference_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtranslation_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_group_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseries_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-50a37061cb58>\u001b[0m in \u001b[0;36mcalculate_recall\u001b[1;34m(ref, candidate, group_size)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mrouge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRouge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrouge_metric\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrouge_stat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0moutcome\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrouge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutcome\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrouge_metric\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrouge_stat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Deep_learning\\lib\\site-packages\\rouge\\rouge.py\u001b[0m in \u001b[0;36mget_scores\u001b[1;34m(self, hyps, refs, avg, ignore_empty)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_avg_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Deep_learning\\lib\\site-packages\\rouge\\rouge.py\u001b[0m in \u001b[0;36m_get_scores\u001b[1;34m(self, hyps, refs)\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRouge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAVAILABLE_METRICS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 sc = fn(\n\u001b[0m\u001b[0;32m    118\u001b[0m                     \u001b[0mhyp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                     \u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Deep_learning\\lib\\site-packages\\rouge\\rouge.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(hyp, ref, **k)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mDEFAULT_METRICS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"rouge-1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rouge-2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rouge-l\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     AVAILABLE_METRICS = {\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[1;34m\"rouge-1\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrouge_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrouge_n\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[1;34m\"rouge-2\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrouge_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrouge_n\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;34m\"rouge-l\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Deep_learning\\lib\\site-packages\\rouge\\rouge_score.py\u001b[0m in \u001b[0;36mrouge_n\u001b[1;34m(evaluated_sentences, reference_sentences, n, raw_results, exclusive)\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hypothesis is empty.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreference_sentences\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Reference is empty.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     evaluated_ngrams = _get_word_ngrams(\n",
      "\u001b[1;31mValueError\u001b[0m: Reference is empty."
     ]
    }
   ],
   "source": [
    "data = main(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "      <th>bleu_w1</th>\n",
       "      <th>bleu_w2</th>\n",
       "      <th>rouge_recall_w1</th>\n",
       "      <th>rouge_precision_w1</th>\n",
       "      <th>rouge_f1_w1</th>\n",
       "      <th>rouge_precision_w2</th>\n",
       "      <th>rouge_recall_w2</th>\n",
       "      <th>rouge_f1_w2</th>\n",
       "      <th>BLEURT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr Zeitlupentempo maßen sie, als sie vor Spit...</td>\n",
       "      <td>Her timeless pace measures them when they equi...</td>\n",
       "      <td>Their slow speed was measured by researchers o...</td>\n",
       "      <td>-0.345024</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>-0.369962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Er sagte, dass die Bereiche ruhige Treffpunkte...</td>\n",
       "      <td>He said the areas offer quiet meeting points b...</td>\n",
       "      <td>He said the spaces provided calm meeting point...</td>\n",
       "      <td>0.903800</td>\n",
       "      <td>97.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.702672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Für die Geschäftsleute an der B 27 ist es nur ...</td>\n",
       "      <td>For businessmen at the B 27, it's only a small...</td>\n",
       "      <td>This is only a small consolation for businesse...</td>\n",
       "      <td>0.700503</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.447156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diese Fähigkeit sei möglicherweise angeboren o...</td>\n",
       "      <td>This ability may be born or developed with gen...</td>\n",
       "      <td>This ability may be innate, or may develop as ...</td>\n",
       "      <td>-1.256572</td>\n",
       "      <td>51.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.311790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weil sie Wassertemperaturen um die sechs Grad ...</td>\n",
       "      <td>Because they prefer water temperatures around ...</td>\n",
       "      <td>They generally only come to the surface in win...</td>\n",
       "      <td>0.293909</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.504052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Ihr Zeitlupentempo maßen sie, als sie vor Spit...   \n",
       "1  Er sagte, dass die Bereiche ruhige Treffpunkte...   \n",
       "2  Für die Geschäftsleute an der B 27 ist es nur ...   \n",
       "3  Diese Fähigkeit sei möglicherweise angeboren o...   \n",
       "4  Weil sie Wassertemperaturen um die sechs Grad ...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Her timeless pace measures them when they equi...   \n",
       "1  He said the areas offer quiet meeting points b...   \n",
       "2  For businessmen at the B 27, it's only a small...   \n",
       "3  This ability may be born or developed with gen...   \n",
       "4  Because they prefer water temperatures around ...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  Their slow speed was measured by researchers o... -0.345024       76.0   \n",
       "1  He said the spaces provided calm meeting point...  0.903800       97.5   \n",
       "2  This is only a small consolation for businesse...  0.700503       94.0   \n",
       "3  This ability may be innate, or may develop as ... -1.256572       51.5   \n",
       "4  They generally only come to the surface in win...  0.293909       87.0   \n",
       "\n",
       "   annotators   bleu_w1   bleu_w2  rouge_recall_w1  rouge_precision_w1  \\\n",
       "0           1  0.250000  0.200000         0.266667            0.250000   \n",
       "1           2  0.750000  0.636364         0.750000            0.750000   \n",
       "2           1  0.650000  0.285714         0.545455            0.545455   \n",
       "3           2  0.461538  0.230769         0.600000            0.428571   \n",
       "4           2  0.722222  0.333333         0.600000            0.631579   \n",
       "\n",
       "   rouge_f1_w1  rouge_precision_w2  rouge_recall_w2  rouge_f1_w2    BLEURT  \n",
       "0     0.258065            0.200000         0.214286     0.206897 -0.369962  \n",
       "1     0.750000            0.636364         0.636364     0.636364  0.702672  \n",
       "2     0.545455            0.285714         0.285714     0.285714  0.447156  \n",
       "3     0.500000            0.230769         0.333333     0.272727  0.311790  \n",
       "4     0.615385            0.277778         0.263158     0.270270  0.504052  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_CV_pipe(x_train, y_train, model, n_splits = 5):\n",
    "    all_scores = []\n",
    "    # set up k-fold\n",
    "    kf = KFold(n_splits=5)\n",
    "    oof_prediction = np.zeros((len(scores),))\n",
    "    test_preds = 0\n",
    "    for  _, (trn_idx, val_idx) in tqdm(enumerate(kf.split(scores, data['z-score']))):\n",
    "        # set up the splitted data\n",
    "        train       , val        = scores.loc[trn_idx,:], scores.loc[val_idx,:]\n",
    "        train_target, val_target = data['z-score'][trn_idx], data['z-score'][val_idx]      \n",
    "        #print(train,val)\n",
    "        # encode     \n",
    "        # model fitting\n",
    "        model.fit(train, train_target)\n",
    "        # get predicted values for oof data and whole test set\n",
    "        temp_oof = model.predict(val)\n",
    "        # get predicted values for whole data set aggregate from each fold iter\n",
    "        oof_prediction[val_idx] = temp_oof    \n",
    "        fold_score = pd.Series(val_target).corr(pd.Series(temp_oof,index = val_idx),method='pearson')\n",
    "        print(fold_score)\n",
    "        all_scores.append(fold_score)               \n",
    "    return  oof_prediction, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 120,\n",
    "          'max_depth': 6,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-0de1d9b2030f>:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for  _, (trn_idx, val_idx) in tqdm(enumerate(kf.split(scores, data['z-score']))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9fed56825a434c9532f8672d044548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40333461356646244\n",
      "0.43235953387601506\n",
      "0.4014679954701772\n",
      "0.3699752559454467\n",
      "0.3873631673991355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40111958618070875"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scores = pd.DataFrame(scaler.fit_transform(data.loc[:,'bleu_w1':]),columns=data.loc[:,'bleu_w1':].columns, index = data.loc[:,'bleu_w1':].index)\n",
    "model = ensemble.GradientBoostingRegressor(**params)\n",
    "oof_prediction, all_scores = kfold_CV_pipe(scores,data['z-score'],model)\n",
    "\n",
    "data['z-score'].corr(pd.Series(oof_prediction,index = data.index),method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bleurt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint bleurt\\test_checkpoint.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint dbleurt_tiny\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:dbleurt_tiny\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"bleurt\\\\test_checkpoint\"\n",
    "scorer = bleurt_score.BleurtScorer(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = getCSV(filePath)\n",
    "references = csv.reference\n",
    "candidates = csv.translation\n",
    "#scores_bluert = scorer.score(references=references, candidates=candidates)\n",
    "scores_bluert = [scorer.score(references=[row[\"reference\"]],candidates= [row[\"translation\"]])[0] for idx, row in csv.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BLEURT'] = scores_bluert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scores = pd.DataFrame(scaler.fit_transform(data.loc[:,'bleu_w1':]),columns=data.loc[:,'bleu_w1':].columns, index = data.loc[:,'bleu_w1':].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu_w1</th>\n",
       "      <th>bleu_w2</th>\n",
       "      <th>rouge_recall_w1</th>\n",
       "      <th>rouge_precision_w1</th>\n",
       "      <th>rouge_f1_w1</th>\n",
       "      <th>rouge_precision_w2</th>\n",
       "      <th>rouge_recall_w2</th>\n",
       "      <th>rouge_f1_w2</th>\n",
       "      <th>BLEURT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.264540</td>\n",
       "      <td>0.137482</td>\n",
       "      <td>0.634414</td>\n",
       "      <td>1.195416</td>\n",
       "      <td>0.948848</td>\n",
       "      <td>0.158922</td>\n",
       "      <td>-0.079202</td>\n",
       "      <td>0.044152</td>\n",
       "      <td>-0.028511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.465324</td>\n",
       "      <td>0.771770</td>\n",
       "      <td>0.064105</td>\n",
       "      <td>0.398461</td>\n",
       "      <td>0.256429</td>\n",
       "      <td>0.802442</td>\n",
       "      <td>0.549969</td>\n",
       "      <td>0.691346</td>\n",
       "      <td>-0.406516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.141584</td>\n",
       "      <td>0.737533</td>\n",
       "      <td>1.018991</td>\n",
       "      <td>0.591662</td>\n",
       "      <td>0.837755</td>\n",
       "      <td>0.767706</td>\n",
       "      <td>1.044318</td>\n",
       "      <td>0.921315</td>\n",
       "      <td>0.821842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.067486</td>\n",
       "      <td>-0.186870</td>\n",
       "      <td>0.966340</td>\n",
       "      <td>0.162326</td>\n",
       "      <td>0.550251</td>\n",
       "      <td>-0.170150</td>\n",
       "      <td>0.220403</td>\n",
       "      <td>0.009019</td>\n",
       "      <td>-1.462404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.205764</td>\n",
       "      <td>-0.803139</td>\n",
       "      <td>-0.980406</td>\n",
       "      <td>-1.358927</td>\n",
       "      <td>-1.208427</td>\n",
       "      <td>-0.820398</td>\n",
       "      <td>-0.646875</td>\n",
       "      <td>-0.743953</td>\n",
       "      <td>-0.455236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11580</th>\n",
       "      <td>-0.094127</td>\n",
       "      <td>0.458745</td>\n",
       "      <td>0.064105</td>\n",
       "      <td>-0.132842</td>\n",
       "      <td>-0.016103</td>\n",
       "      <td>0.536640</td>\n",
       "      <td>0.691212</td>\n",
       "      <td>0.631039</td>\n",
       "      <td>0.638268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11581</th>\n",
       "      <td>-0.115924</td>\n",
       "      <td>-0.747114</td>\n",
       "      <td>-0.294979</td>\n",
       "      <td>-0.248343</td>\n",
       "      <td>-0.254568</td>\n",
       "      <td>-0.965907</td>\n",
       "      <td>-0.978018</td>\n",
       "      <td>-0.973118</td>\n",
       "      <td>-0.927007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11582</th>\n",
       "      <td>0.604318</td>\n",
       "      <td>1.269765</td>\n",
       "      <td>0.402066</td>\n",
       "      <td>0.444661</td>\n",
       "      <td>0.460827</td>\n",
       "      <td>0.852966</td>\n",
       "      <td>0.819614</td>\n",
       "      <td>0.860205</td>\n",
       "      <td>1.008398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11583</th>\n",
       "      <td>0.508525</td>\n",
       "      <td>0.712549</td>\n",
       "      <td>0.064105</td>\n",
       "      <td>0.566241</td>\n",
       "      <td>0.332870</td>\n",
       "      <td>0.742359</td>\n",
       "      <td>0.412011</td>\n",
       "      <td>0.585206</td>\n",
       "      <td>-0.565352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11584</th>\n",
       "      <td>0.665128</td>\n",
       "      <td>0.165283</td>\n",
       "      <td>-0.000671</td>\n",
       "      <td>0.141970</td>\n",
       "      <td>0.097067</td>\n",
       "      <td>0.008489</td>\n",
       "      <td>-0.063705</td>\n",
       "      <td>-0.016252</td>\n",
       "      <td>0.140559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11585 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bleu_w1   bleu_w2  rouge_recall_w1  rouge_precision_w1  rouge_f1_w1  \\\n",
       "0      1.264540  0.137482         0.634414            1.195416     0.948848   \n",
       "1      0.465324  0.771770         0.064105            0.398461     0.256429   \n",
       "2      1.141584  0.737533         1.018991            0.591662     0.837755   \n",
       "3     -0.067486 -0.186870         0.966340            0.162326     0.550251   \n",
       "4     -1.205764 -0.803139        -0.980406           -1.358927    -1.208427   \n",
       "...         ...       ...              ...                 ...          ...   \n",
       "11580 -0.094127  0.458745         0.064105           -0.132842    -0.016103   \n",
       "11581 -0.115924 -0.747114        -0.294979           -0.248343    -0.254568   \n",
       "11582  0.604318  1.269765         0.402066            0.444661     0.460827   \n",
       "11583  0.508525  0.712549         0.064105            0.566241     0.332870   \n",
       "11584  0.665128  0.165283        -0.000671            0.141970     0.097067   \n",
       "\n",
       "       rouge_precision_w2  rouge_recall_w2  rouge_f1_w2    BLEURT  \n",
       "0                0.158922        -0.079202     0.044152 -0.028511  \n",
       "1                0.802442         0.549969     0.691346 -0.406516  \n",
       "2                0.767706         1.044318     0.921315  0.821842  \n",
       "3               -0.170150         0.220403     0.009019 -1.462404  \n",
       "4               -0.820398        -0.646875    -0.743953 -0.455236  \n",
       "...                   ...              ...          ...       ...  \n",
       "11580            0.536640         0.691212     0.631039  0.638268  \n",
       "11581           -0.965907        -0.978018    -0.973118 -0.927007  \n",
       "11582            0.852966         0.819614     0.860205  1.008398  \n",
       "11583            0.742359         0.412011     0.585206 -0.565352  \n",
       "11584            0.008489        -0.063705    -0.016252  0.140559  \n",
       "\n",
       "[11585 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for normal score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>pcorr</th>\n",
       "      <th>kendallcorr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bleu_w1</th>\n",
       "      <td>1.053754</td>\n",
       "      <td>0.404921</td>\n",
       "      <td>0.271061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bleu_w2</th>\n",
       "      <td>1.079262</td>\n",
       "      <td>0.390275</td>\n",
       "      <td>0.272864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge_recall_w1</th>\n",
       "      <td>1.113440</td>\n",
       "      <td>0.370650</td>\n",
       "      <td>0.249050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge_precision_w1</th>\n",
       "      <td>1.019766</td>\n",
       "      <td>0.424436</td>\n",
       "      <td>0.286600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge_f1_w1</th>\n",
       "      <td>1.035963</td>\n",
       "      <td>0.415136</td>\n",
       "      <td>0.279233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge_precision_w2</th>\n",
       "      <td>1.089080</td>\n",
       "      <td>0.384637</td>\n",
       "      <td>0.267882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge_recall_w2</th>\n",
       "      <td>1.135497</td>\n",
       "      <td>0.357986</td>\n",
       "      <td>0.247705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge_f1_w2</th>\n",
       "      <td>1.100779</td>\n",
       "      <td>0.377920</td>\n",
       "      <td>0.260021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEURT</th>\n",
       "      <td>0.940529</td>\n",
       "      <td>0.469932</td>\n",
       "      <td>0.329338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mse     pcorr  kendallcorr\n",
       "bleu_w1             1.053754  0.404921     0.271061\n",
       "bleu_w2             1.079262  0.390275     0.272864\n",
       "rouge_recall_w1     1.113440  0.370650     0.249050\n",
       "rouge_precision_w1  1.019766  0.424436     0.286600\n",
       "rouge_f1_w1         1.035963  0.415136     0.279233\n",
       "rouge_precision_w2  1.089080  0.384637     0.267882\n",
       "rouge_recall_w2     1.135497  0.357986     0.247705\n",
       "rouge_f1_w2         1.100779  0.377920     0.260021\n",
       "BLEURT              0.940529  0.469932     0.329338"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = np.array([])\n",
    "pcorr = np.array([])\n",
    "kendallcorr = np.array([])\n",
    "metrics = scores.columns\n",
    "for col in scores.columns:\n",
    "    mse = np.append(mse,mean_squared_error(data['z-score'],scores[col]))\n",
    "    pcorr = np.append(pcorr,data['z-score'].corr(scores[col],method='pearson'))\n",
    "    kendallcorr = np.append(kendallcorr,data['z-score'].corr(scores[col],method='kendall'))\n",
    "    \n",
    "pd.DataFrame({'mse':mse,'pcorr':pcorr,'kendallcorr':kendallcorr},index = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= scores\n",
    "y= data['z-score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=13)\n",
    "\n",
    "params = {'n_estimators': 120,\n",
    "          'max_depth': 6,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.01, max_depth=6, min_samples_split=5,\n",
       "                          n_estimators=120)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ensemble.GradientBoostingRegressor(**params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on train set: 0.5194\n",
      "The mean squared error (MSE) on test set: 0.5888\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_train, model.predict(X_train))\n",
    "print(\"The mean squared error (MSE) on train set: {:.4f}\".format(mse))\n",
    "mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = pd.Series(reg.predict(X_test),index = y_test.index,name = 'Predict_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_score =pd.merge(data['z-score'],y_predict,left_index= True,right_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 0.6510223507551757\n",
      "pcorr 0.5068492287785946\n",
      "kendall 0.3629815342755539\n"
     ]
    }
   ],
   "source": [
    "print('mse',mean_squared_error(merged_score['z-score'],merged_score['Predict_score']))\n",
    "print('pcorr',merged_score['z-score'].corr(merged_score['Predict_score'],method='pearson'))\n",
    "print('kendall',merged_score['z-score'].corr(merged_score['Predict_score'],method='kendall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_results(scores,z_score)\n",
    "    mse = np.array([])\n",
    "    pcorr = np.array([])\n",
    "    kendallcorr = np.array([])\n",
    "    metrics = scores.columns\n",
    "    for col in scores.columns:\n",
    "        mse = np.append(mse,mean_squared_error(z_score,scores[col]))\n",
    "        pcorr = np.append(pcorr,z_score.corr(scores[col],method='pearson'))\n",
    "        kendallcorr = np.append(kendallcorr,z_score.corr(scores[col],method='kendall'))\n",
    "    pd.DataFrame({'mse':mse,'pcorr':pcorr,'kendallcorr':kendallcorr},index = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_CV_pipe(x_train, y_train, model, n_splits = 5):\n",
    "    all_scores = []\n",
    "    # set up k-fold\n",
    "    kf = KFold(n_splits=5)\n",
    "    oof_prediction = np.zeros((len(scores),))\n",
    "    test_preds = 0\n",
    "    for  _, (trn_idx, val_idx) in tqdm(enumerate(kf.split(scores, data['z-score']))):\n",
    "        # set up the splitted data\n",
    "        train       , val        = scores.loc[trn_idx,:], scores.loc[val_idx,:]\n",
    "        train_target, val_target = data['z-score'][trn_idx], data['z-score'][val_idx]      \n",
    "        #print(train,val)\n",
    "        # encode     \n",
    "        # model fitting\n",
    "        model.fit(train, train_target)\n",
    "        # get predicted values for oof data and whole test set\n",
    "        temp_oof = model.predict(val)\n",
    "        # get predicted values for whole data set aggregate from each fold iter\n",
    "        oof_prediction[val_idx] = temp_oof    \n",
    "        fold_score = pd.Series(val_target).corr(pd.Series(temp_oof,index = val_idx),method='pearson')\n",
    "        print(fold_score)\n",
    "        all_scores.append(fold_score)               \n",
    "    return  oof_prediction, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-82-0de1d9b2030f>:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for  _, (trn_idx, val_idx) in tqdm(enumerate(kf.split(scores, data['z-score']))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ee7485735b4c5f88c1b0acc583277b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5151114418970998\n",
      "0.45190028203146526\n",
      "0.5390717229564809\n",
      "0.5361070573926131\n",
      "0.5445100717320295\n"
     ]
    }
   ],
   "source": [
    "model = ensemble.GradientBoostingRegressor(**params)\n",
    "oof_prediction, all_scores = kfold_CV_pipe(scores,data['z-score'],model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5173917437819486"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['z-score'].corr(pd.Series(oof_prediction,index = data.index),method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
